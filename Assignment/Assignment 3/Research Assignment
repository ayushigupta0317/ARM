1.)  Yes, fractional part plays a role in defining precision of floating point number, 
where the precision is the total number of digits in significand. 
The Mantissa(or significand) is composed of an implicit leading bit (left of the radix point and is not stored) 
and the fraction bits (to the right of the radix point). Single precision binary floating point format has significand 
precision of 24 bits(23 explicitly stored) and double precision binary floating point format has significand precision of 53 bits
(52 explicitly stored). More fractional bits means more precision.
For example, the decimal number 601 can be represented as any of these:
0.601 × 10^3           6.01 × 10^2             60.1 × 10^1   ……      
In order to maximize the quantity of representable numbers, it is stored in normalized form, 
where the radix point is placed after the first non-zero digit(for binary no. it is 1). 
In normalized form, 601 is represented as 6.01 × 10^2 . So, here the precision is 3.
Considering another example, 1.00001 x 2^3 , here precision is 6.


2.)  As per IEEE 754 standards, a normal number is a finite nonzero floating-point number with magnitude
greater than or equal to a minimum value  b^emin ,where b is the radix and emin is the minimum exponent. 
Normal numbers can use the full precision available in a format.

And, when all the exponent bits are 0 and the leading hidden bit of the significand is 0, 
then the floating point number is called a subnormal number or non-zero floating-point numbers having magnitude less than b^emin is a 
subnormal number.
                                                      
                                                      B^emin
                           0 |--------------------------|--------------------------------
                                 Subnormal Values                       Normal Values  
                                 
                                 
3.)  IEEE 754 standard defines five rounding rules. The first two rules round to a nearest value; 
the others are called directed roundings:

a.)	Round to nearest, ties to even – rounds to the nearest value and if the number falls midway, 
it is rounded to the nearest value with an even least significant digit; 
this is the default for binary floating point and the recommended default for decimal.
Eg:    +13.5 is rounded off to +14.0
       -13.5 is rounded off to -14.0
       +14.5 is rounded off to +14.0
       -14.5 is rounded off to -14.0

b.)	Round to nearest, ties away from zero – rounds to the nearest value and if the number falls midway,
it is rounded to the nearest value above (for positive numbers) or below (for negative numbers).
Eg:    +13.5 is rounded off to +14.0
       -13.5 is rounded off to -14.0
       +14.5 is rounded off to +15.0
       -14.5 is rounded off to -15.0
       
c.)	Round toward 0 – directed rounding towards zero (also known as truncation).
Eg:    +13.5 is rounded off to +13.0
       -13.5 is rounded off to -13.0
       +14.5 is rounded off to +14.0
       -14.5 is rounded off to -14.0
       
d.)	Round toward +∞ – directed rounding towards positive infinity (also known as rounding up or ceiling).
Eg:    +13.5 is rounded off to +14.0
       -13.5 is rounded off to -13.0
       +14.5 is rounded off to +15.0
       -14.5 is rounded off to -14.0
       
e.)	Round toward −∞ – directed rounding towards negative infinity (also known as rounding down or floor).
Eg:    +13.5 is rounded off to +13.0
       -13.5 is rounded off to -14.0
       +14.5 is rounded off to +14.0
       -14.5 is rounded off to -15.0

